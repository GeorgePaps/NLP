# NLP

## General Remarks

This is a repository where I explore Natural Language Processing (NLP).

Although I have some background in machine learning and natural
language processing,
I will try to approach this topic with the eyes of a newcomer. This means thinking and hypothesizing first; reading, learning and applying second.
I believe that this approach can help  in the learning process.
This repository will track part of my learning journey.

> Thinking and hypothesizing first; reading, learning and applying second.

## Approach

I will start exploring the topic somewhat organically and my approach will evolve along the way.
For time being I will start by exploring this very interesting [repository](https://github.com/keon/awesome-nlp) and reading [this](https://web.stanford.edu/~jurafsky/slp3/ed3book_jan122022.pdf) and [this](https://www.amazon.com/Natural-Language-Processing-PyTorch-Applications/dp/1491978236/) book. 
Additionally, I will be following this [udemy](https://www.udemy.com/course/nlp-natural-language-processing-with-python/) course. 

---

## What is NLP

On a higher level I like to think of what NLP is in the light of this  intelligence definition. 

> Intelligence: the ability to perceive or deduce information, retain it as knowledge, and apply it to make decisions. 

A more specific definition of NLP would be:

> NLP refers to a set of techniques involving the application of statistical methods, with ot without insights from linguistics, to understand text for the sake of solving real-world tasks. 
This "understanding" of of text is mainly derived by transforming texts to computational representations, 
which are discrete or continuous combinatorial structures such as vectors or tensors, graphs, and trees.[1] 

## The Computational Graphs 

A very interesting concept I encountered early in this book[1] is that of computational graph. In thw words of the authors:

> Put simply, deep learning enables one to efficiently learn representations from data using an abstraction called the computational graph and numerical optimization techniques.[1]

## Supervised Learning Paradigm 


## Observation and Target Encoding 

A very interesting quote I encountered[1] regarding target encoding is the following:

>In deep learning, it is rare to see inputs encoded using euristic representations like TF-IDF because **the goal is to learn a representation**.


---

## Bibliography 

### Books 

1. [Natural Language Processing with PyTorch: Build Intelligent Language Applications Using Deep Learning](https://www.amazon.com/Natural-Language-Processing-PyTorch-Applications/dp/1491978236/) by Delip Rao and Brian McMahan

### Repositories 

- R1. [awesome-nlp](https://github.com/keon/awesome-nlp)
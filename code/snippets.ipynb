{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Snippets for Natural Language Programming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Contents\n",
    "\n",
    "- 1 One-hot representation with scikit-lear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating one-hot representation with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0. General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    \"\"\"A function used to give information \"\"\"\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n {}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "# describe(torch.rand(2,3)) # create a tensor from uniform random distribution\n",
    "# describe(torch.randn(2,3)) # create a tensor from random normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create tensors all filled with the same scalar. For creating tensor of zeros or ones, we have built-in functions, and for filling it with specific values, we can use the fill_() method. \n",
    "\n",
    "Any PyTorch method with an underscore refers to an in-place operation; that is, it modifies the content in place without creating a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a filled tensor \n",
    "\n",
    "import torch \n",
    "# describe(torch.zeros(2,3))\n",
    "x = torch.ones(2,3)\n",
    "# describe(x)\n",
    "x.fill_(5)\n",
    "# describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and initializing a tensor from lists\n",
    "\n",
    "x = torch.tensor([[1,2,3],\n",
    "                  [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      " tensor([[0.9334, 0.9989, 0.0594],\n",
      "        [0.4688, 0.8958, 0.8736]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# We can also create from Numpy but pay attention that in that case the type will\n",
    "# be torch.DoubleTensor instead of the torch.FloatTensor\n",
    "\n",
    "import numpy as np\n",
    "npy = np.random.rand(2, 3)\n",
    "describe(torch.from_numpy(npy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert a tensor to a different type(float, long, double, etc. ) \n",
    "by specifying it at initialization or later using one of the typecasting methods. \n",
    "There are two ways to specify the initialization type: either by directly calling \n",
    "the constructor of a specific tensor type, such as FloatTensor or LongTensor, or \n",
    "using a special method, torch.tensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
    "x = x.long()\n",
    "x = torch.tensor([[1, 2, 3],[4, 5, 6]], dtype = torch.int64)\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the shape property and size() method of a tensor object to access the \n",
    "measurements of its dimensions. \n",
    "The two ways of accessing these measurements are mostly synonymous. \n",
    "Inspecting the shape of the tensor is an indispansable tool in debugging PyTorch code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have created your tensors, you can operate on them like you would do with \n",
    "traditional programming language types, like +,-,*,/. \n",
    "Instead of the operators, you can also use functions like .add()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      " tensor([[-0.2230,  1.0111,  1.2863],\n",
      "        [ 1.3616, -0.0561,  0.6778]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      " tensor([[-0.4461,  2.0223,  2.5726],\n",
      "        [ 2.7233, -0.1122,  1.3555]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      " tensor([[-0.4461,  2.0223,  2.5726],\n",
      "        [ 2.7233, -0.1122,  1.3555]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "describe(x)\n",
    "describe(torch.add(x,x))\n",
    "describe(x+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([6])\n",
      "Values: \n",
      " tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      " tensor([3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x, dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      " tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(x,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Indexing, slicing, and joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      " tensor([[0, 1]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2,3)\n",
    "describe(x[:1,:2])\n",
    "describe(x[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      " tensor([[0, 2],\n",
      "        [3, 5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0,2])\n",
    "describe(torch.index_select(x, dim=1,index = indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      " tensor([[0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0,0,1])\n",
    "describe(torch.index_select(x, dim=0,index = indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      " tensor([0, 4])\n"
     ]
    }
   ],
   "source": [
    "row_indices = torch.arange(2).long()\n",
    "col_indices = torch.LongTensor([0,1])\n",
    "describe(x[row_indices, col_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indices are a LongTensor; this is a requirement for indexing using PyTorch functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2],\n",
       "         [3, 4, 5]],\n",
       "\n",
       "        [[0, 1, 2],\n",
       "         [3, 4, 5]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(6).view(2,3)\n",
    "torch.cat([x,x], dim = 0)\n",
    "torch.cat([x,x], dim = 1)\n",
    "torch.stack([x,x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python also implements highly efficient linear algebra operations on tensors, such as multiplication, inverse, and trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      " tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [1, 2]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.arange(6).view(2,3)\n",
    "describe(x1)\n",
    "x2 = torch.ones(3,2).long()\n",
    "x2[:,1] += 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6],\n",
       "        [12, 24]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Tensors and Computational Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensor class encapsulates the data (the tensor itself) and a range of operations, such as algebraic operations, indexing, and reshaping operations. \n",
    "However, when the requires_grad Boolean flag is set to True on a tensor, \n",
    "bookkeeping operations are enabled that can track the gradient at the tensor as well as the gradient function, \n",
    "both of which are needed to facilitate the fradient-based learning discussed in \"The Supervised Learning Paradigm\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.ones(2,3, requires_grad=True)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DB676EB\\Projects\\NLP\\NLPvenv\\lib\\site-packages\\torch\\_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten\\src\\ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "print(y.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.mean()\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create a tensor with requires_grad = True, you are requiring PyTorch to manage bookkeeping information that computes gradients. \n",
    "First, PyTorch will keep track fo the values of the forward pass.\n",
    "Then, at the end of the computations, a single scalar is used to compute a backward pass. \n",
    "The backward pass is initiated using the backward() method on a tensor resulting from the evaluation of a loss function. \n",
    "The backward pass computes a gradient value for a tensor object that participated in the forward pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the gradient is a value that represents the slope of a function output with respect to the function input. \n",
    "IN the computational graph setting, gradients exist for each parameter in the model and can be thought of as the parameter's contribution to the error signal.\n",
    "In PyTorch, you can access the gradients for the nodes in the computational graph by using the .grad member variable. \n",
    "Optimisers use the .grad variable to update the values of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 CUDA Tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been allocating our tensors on the CPU memory. When doing linear algebra operations, it might make sense to utilize a GPU, if you have one. \n",
    "To use a GPU you need first to allocate the tensor on the GPU's memory. \n",
    "Access to the GPUs is via a specialized API called CUDA. \n",
    "The CUDA API was created by NVIDIA and is limited to use on only NVIDIA GPUs. \n",
    "PyTorch offers CUDA tensor objects that are indistinguishable in use from the regular CPU-bound tensors except for the way they are allocated internally. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTOrch makes it very easy to create these CUDA tensors, transfering the tensor from the CPU to the GPU while maintating its underlying type. \n",
    "THe preffered method in PyTorch is to be device agnostic and write code that works wheter it's on GPU or the CPU. \n",
    "You can check whether a GPU is available by using torch.cuda.is_available() and retrieve the device name with torch.decice().\n",
    "Then, all future tensors are instantiated and moved to the target device by using the .to(device) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To operate on CUDA and non-CUDA objects, we need to ensure that they are not on the same device. If we don't, the computations will break. \n",
    "\n",
    "Keep in mind that it is expensive to move data back and forth from the GPU. \n",
    "Therefore, the typical procedure involves doing many of the parallelizable computations on the GPU and then transferring just the final result back to the CPU. \n",
    "This will allow you to fully utilize the GPUs. \n",
    "If you have several CUDA-visible devices, \n",
    "the best practice is to use the CUDA_VISIBLE_DEVICES environment variable when executing the program."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c5955f3c69348582e3b0db013a3fba764896497ab638e5267f4b4368a25c854"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('NLPvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
